{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ef2ebc",
   "metadata": {},
   "source": [
    "# Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c351808",
   "metadata": {},
   "source": [
    "## M√©tricas de desempenho tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd23ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def detectar_tipo_tarefa(y):\n",
    "    y_array = np.array(y)\n",
    "\n",
    "    if np.issubdtype(y_array.dtype, np.floating):\n",
    "        return \"regressao\"\n",
    "\n",
    "    n_classes = len(np.unique(y_array))\n",
    "    if n_classes == 2:\n",
    "        return \"binaria\"\n",
    "    elif n_classes > 2:\n",
    "        return \"multiclasse\"\n",
    "    return \"desconhecido\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e984aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def desempenho_tradicional_binario(y_true, y_pred, explain=False):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Acur√°cia:  {acc:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Acur√°cia: propor√ß√£o de acertos no total de exemplos. Boa se > 0.80, mas pode enganar em dados desbalanceados.\")\n",
    "\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    print(f\"Precis√£o:  {prec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Precis√£o: entre os que foram preditos como positivos, quantos realmente s√£o. Boa se voc√™ quer evitar falsos positivos.\")\n",
    "\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Recall: entre os positivos reais, quantos foram detectados. Boa se voc√™ quer evitar falsos negativos.\")\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ F1-Score: m√©dia harm√¥nica entre precis√£o e recall. Equilibra ambos quando h√° desbalanceamento.\")\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1329ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def desempenho_tradicional_multiclasse(y_true, y_pred, explain=False):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Acur√°cia:  {acc:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Acur√°cia: propor√ß√£o de acertos entre todas as classes. Boa se > 0.80, mas cuidado com desbalanceamento.\")\n",
    "\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    print(f\"Precis√£o (macro): {prec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Precis√£o: m√©dia da precis√£o de cada classe. Mostra se o modelo √© justo com todas as classes.\")\n",
    "\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    print(f\"Recall (macro):   {rec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Recall: m√©dia do recall de cada classe. Mede cobertura m√©dia de cada classe verdadeira.\")\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"F1-Score (macro): {f1:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ F1-Score: m√©dia harm√¥nica entre precis√£o e recall para todas as classes.\")\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33debcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def desempenho_tradicional_regressao(y_true, y_pred, explain=False):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"R2:  {r2:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ R2: qu√£o bem o modelo explica a vari√¢ncia. 1.0 √© perfeito. Pode ser negativo se o modelo for ruim.\")\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ MSE: erro quadr√°tico m√©dio. Penaliza mais os erros grandes. Quanto menor, melhor.\")\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ MAE: erro absoluto m√©dio. Indica o erro m√©dio em termos absolutos. Quanto menor, melhor.\")\n",
    "    return r2, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa18632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desempenho_tradicional(model, X_test, y_test, explain=False):\n",
    "    tipo = detectar_tipo_tarefa(y_test)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if tipo == \"binaria\":\n",
    "        return desempenho_tradicional_binario(y_test, y_pred, explain)\n",
    "    elif tipo == \"multiclasse\":\n",
    "        return desempenho_tradicional_multiclasse(y_test, y_pred, explain)\n",
    "    elif tipo == \"regressao\":\n",
    "        return desempenho_tradicional_regressao(y_test, y_pred, explain)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Tipo de tarefa n√£o reconhecido.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b84a3e",
   "metadata": {},
   "source": [
    "## Explicabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4cbafb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (4214720753.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef explain_model(model, X, max_display=10, nome=None, target_name=None)):\u001b[39m\n                                                                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "def explain_model(model, X, max_display=10, nome=None, target_name=None):\n",
    "    \"\"\"\n",
    "    Explica modelos de √°rvore com SHAP (suporta classificadores e regress√µes).\n",
    "    \n",
    "    Par√¢metros:\n",
    "        - model: modelo treinado (ex: DecisionTree, GBC, GBR)\n",
    "        - X: dados de entrada (DataFrame ou array)\n",
    "        - max_display: n√∫mero m√°ximo de features no gr√°fico\n",
    "        - nome: t√≠tulo opcional a ser inclu√≠do nos gr√°ficos\n",
    "    \"\"\"\n",
    "    \n",
    "    modelos_problema = isinstance(model, DecisionTreeClassifier)\n",
    "    modelos_sem_problema = isinstance(model, (\n",
    "        GradientBoostingClassifier,\n",
    "        DecisionTreeRegressor,\n",
    "        GradientBoostingRegressor\n",
    "    ))\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    if not modelos_problema:\n",
    "        if not modelos_sem_problema:\n",
    "            print(\"‚ö†Ô∏è Tipo de modelo n√£o identificado, tentando procedimento padr√£o\")\n",
    "            if shap_values.shape != X.shape:\n",
    "                raise AssertionError(f\"shap_values.shape = {shap_values.shape}, X.shape = {X.shape}\")\n",
    "                return\n",
    "        \n",
    "        print(\"üîç Gerando explicabilidade global do modelo...\")\n",
    "\n",
    "        \n",
    "\n",
    "        shap.summary_plot(shap_values, X, plot_type=\"bar\", max_display=max_display, show=False)\n",
    "        if nome:\n",
    "            plt.title(f\"{nome} ‚Äî Import√¢ncia global\")\n",
    "        plt.show()\n",
    "\n",
    "        shap.summary_plot(shap_values, X, max_display=max_display, show=False)\n",
    "        if nome:\n",
    "            plt.title(f\"{nome} ‚Äî Distribui√ß√£o dos impactos\")\n",
    "        plt.show()\n",
    "    \n",
    "    elif isinstance(model, DecisionTreeClassifier):\n",
    "        print(f\"shap_values.shape = {shap_values.shape}, X.shape = {X.shape}\")\n",
    "        class_names = model.classes_\n",
    "\n",
    "        _, _, n_classes = shap_values.shape\n",
    "        for i in range(n_classes):\n",
    "            \n",
    "            print(f\"\\nüìä {target_name}: {i}' ‚Äî Explica√ß√£o global\")\n",
    "            shap.summary_plot(shap_values[:, :, i], X, plot_type=\"bar\", max_display=max_display, show=False)\n",
    "            if nome:\n",
    "                plt.title(f\"{nome} ‚Äî {target_name}: {i}' ‚Äî Import√¢ncia global\")\n",
    "            plt.show()\n",
    "\n",
    "            print(f\"üìà {target_name}: {i}' ‚Äî Distribui√ß√£o dos impactos\")\n",
    "            shap.summary_plot(shap_values[:, :, i], X, max_display=max_display, show=False)\n",
    "            if nome:\n",
    "                plt.title(f\"{nome} ‚Äî {target_name}: {i}' ‚Äî Distribui√ß√£o dos impactos\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def explain_individual(index, model, X_train):\n",
    "    \"\"\"\n",
    "    üß† Explicabilidade local com SHAP (vers√£o waterfall).\n",
    "    Mostra o impacto de cada feature + exibe a probabilidade prevista no gr√°fico.\n",
    "    \"\"\"\n",
    "    # Obter valores SHAP\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    instance = X_train.iloc[[index]]\n",
    "\n",
    "    # Corrigir acesso ao escalar\n",
    "    expected_value = explainer.expected_value[0]\n",
    "    fx = float(shap_values[index].sum() + expected_value)\n",
    "    prob = float(expit(fx))\n",
    "\n",
    "    # Construir explica√ß√£o\n",
    "    explanation = shap.Explanation(\n",
    "        values=shap_values[index],\n",
    "        base_values=expected_value,\n",
    "        data=instance.values[0],\n",
    "        feature_names=instance.columns\n",
    "    )\n",
    "\n",
    "    # Plot com t√≠tulo seguro (sem emoji)\n",
    "    shap.plots.waterfall(explanation, show=False)\n",
    "    plt.title(f\"SHAP Waterfall ‚Äî Inst√¢ncia {index} | Prob. prevista: {prob:.2f}\", fontsize=12)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
