{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ef2ebc",
   "metadata": {},
   "source": [
    "# Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c351808",
   "metadata": {},
   "source": [
    "## M√©tricas de desempenho tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_tipo_tarefa(y):\n",
    "    import numpy as np\n",
    "    y_array = np.array(y)\n",
    "\n",
    "    if np.issubdtype(y_array.dtype, np.floating):\n",
    "        return \"regressao\"\n",
    "\n",
    "    n_classes = len(np.unique(y_array))\n",
    "    if n_classes == 2:\n",
    "        return \"binaria\"\n",
    "    elif n_classes > 2:\n",
    "        return \"multiclasse\"\n",
    "    return \"desconhecido\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e984aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desempenho_tradicional_binario(y_true, y_pred, explain=False):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Acur√°cia:  {acc:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Acur√°cia: propor√ß√£o de acertos no total de exemplos. Boa se > 0.80, mas pode enganar em dados desbalanceados.\")\n",
    "\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    print(f\"Precis√£o:  {prec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Precis√£o: entre os que foram preditos como positivos, quantos realmente s√£o. Boa se voc√™ quer evitar falsos positivos.\")\n",
    "\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Recall: entre os positivos reais, quantos foram detectados. Boa se voc√™ quer evitar falsos negativos.\")\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ F1-Score: m√©dia harm√¥nica entre precis√£o e recall. Equilibra ambos quando h√° desbalanceamento.\")\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desempenho_tradicional_multiclasse(y_true, y_pred, explain=False):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Acur√°cia:  {acc:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Acur√°cia: propor√ß√£o de acertos entre todas as classes. Boa se > 0.80, mas cuidado com desbalanceamento.\")\n",
    "\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    print(f\"Precis√£o (macro): {prec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Precis√£o: m√©dia da precis√£o de cada classe. Mostra se o modelo √© justo com todas as classes.\")\n",
    "\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    print(f\"Recall (macro):   {rec:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ Recall: m√©dia do recall de cada classe. Mede cobertura m√©dia de cada classe verdadeira.\")\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"F1-Score (macro): {f1:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ F1-Score: m√©dia harm√¥nica entre precis√£o e recall para todas as classes.\")\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33debcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desempenho_tradicional_regressao(y_true, y_pred, explain=False):\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"R2:  {r2:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ R2: qu√£o bem o modelo explica a vari√¢ncia. 1.0 √© perfeito. Pode ser negativo se o modelo for ruim.\")\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ MSE: erro quadr√°tico m√©dio. Penaliza mais os erros grandes. Quanto menor, melhor.\")\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    if explain:\n",
    "        print(\"üîπ MAE: erro absoluto m√©dio. Indica o erro m√©dio em termos absolutos. Quanto menor, melhor.\")\n",
    "    return r2, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa18632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desempenho_tradicional(model, X_test, y_test, explain=False):\n",
    "    tipo = detectar_tipo_tarefa(y_test)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if tipo == \"binaria\":\n",
    "        return desempenho_tradicional_binario(y_test, y_pred, explain)\n",
    "    elif tipo == \"multiclasse\":\n",
    "        return desempenho_tradicional_multiclasse(y_test, y_pred, explain)\n",
    "    elif tipo == \"regressao\":\n",
    "        return desempenho_tradicional_regressao(y_test, y_pred, explain)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Tipo de tarefa n√£o reconhecido.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb893b",
   "metadata": {},
   "source": [
    "## Sum√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3587095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dataset(df):\n",
    "    \"\"\"\n",
    "    üìä Gera um sum√°rio completo de estat√≠sticas e estrutura do dataset.\n",
    "\n",
    "    Par√¢metros:\n",
    "    - df: pandas DataFrame\n",
    "\n",
    "    Retorna:\n",
    "    - Imprime m√©tricas descritivas e insights √∫teis sobre as colunas\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(\"üì¶ Tamanho do dataset:\")\n",
    "    print(f\"- Linhas: {df.shape[0]}\")\n",
    "    print(f\"- Colunas: {df.shape[1]}\")\n",
    "    print(\"\\nüìÑ Primeiras 5 linhas:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\nüî¢ Informa√ß√µes b√°sicas:\")\n",
    "    display(df.info())\n",
    "\n",
    "    print(\"\\nüìà Estat√≠sticas descritivas:\")\n",
    "    display(df.describe().T)\n",
    "\n",
    "    print(\"\\nüßæ Colunas categ√≥ricas/dummies:\")\n",
    "    cat_cols = [col for col in df.columns if df[col].nunique() <= 10 and df[col].dtype in [np.int64, np.bool_, np.int32, object]]\n",
    "    for col in cat_cols:\n",
    "        print(f\"- {col}: {df[col].unique()} (n={df[col].nunique()})\")\n",
    "\n",
    "    print(\"\\nüìä Correla√ß√£o entre vari√°veis num√©ricas:\")\n",
    "    corr = df.corr(numeric_only=True)\n",
    "    display(corr.style.background_gradient(cmap='coolwarm', axis=None).format(precision=2))\n",
    "\n",
    "\n",
    "    print(\"\\n‚ö†Ô∏è Colunas com valores nulos:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    if not missing.empty:\n",
    "        display(missing)\n",
    "    else:\n",
    "        print(\"‚úÖ Nenhum valor nulo encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126bbc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_racial(df,race_columns):\n",
    "    from IPython.display import display, HTML\n",
    "\n",
    "    # üìä Loop para exibir totais e distribui√ß√µes lado a lado\n",
    "    for race in race_columns:\n",
    "        print(f\"\\nüìä Ra√ßa: {race}\")\n",
    "        total = df[race].sum()\n",
    "        print(f\"Total de indiv√≠duos: {int(total)}\")\n",
    "\n",
    "        # üìä Gerar tabelas\n",
    "        dist_abs = pd.crosstab(df[race], df['Reincidente'])\n",
    "        dist_pct = pd.crosstab(df[race], df['Reincidente'], normalize='index').round(3)\n",
    "\n",
    "        # üîó Combinar HTML das duas tabelas\n",
    "        html = f\"\"\"\n",
    "        <div style=\"display: flex; gap: 40px;\">\n",
    "            <div>\n",
    "                <b>Distribui√ß√£o absoluta:</b>\n",
    "                {dist_abs.to_html()}\n",
    "            </div>\n",
    "            <div>\n",
    "                <b>Distribui√ß√£o percentual:</b>\n",
    "                {dist_pct.to_html()}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab041935",
   "metadata": {},
   "source": [
    "## M√©tricas de Disparidade/Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b552399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def consistency_score(X, y_pred, k=5):\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \"\"\"\n",
    "    üìè Mede Individual Fairness com base na Consist√™ncia.\n",
    "    Quanto maior, mais justo o modelo.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - X: Features (sem atributo sens√≠vel)\n",
    "    - y_pred: Sa√≠das do modelo (classes ou probabilidades)\n",
    "    - k: N√∫mero de vizinhos\n",
    "\n",
    "    Retorna:\n",
    "    - M√©dia da similaridade de predi√ß√µes entre vizinhos\n",
    "    \"\"\"\n",
    "    nn = NearestNeighbors(n_neighbors=k+1)  # +1 porque inclui o pr√≥prio ponto\n",
    "    nn.fit(X)\n",
    "    neighbors = nn.kneighbors(X, return_distance=False)[:, 1:]  # Remove o pr√≥prio √≠ndice\n",
    "\n",
    "    diffs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        neighbor_preds = y_pred[neighbors[i]]\n",
    "        diffs.append(np.mean(np.abs(y_pred[i] - neighbor_preds)))\n",
    "\n",
    "    return 1 - np.mean(diffs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b84a3e",
   "metadata": {},
   "source": [
    "## Explicabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4cbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model(model, X, max_display=10, nome=None, target_name=None):\n",
    "    import shap\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "    from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "    \"\"\"\n",
    "    Explica modelos de √°rvore com SHAP (suporta classificadores e regress√µes).\n",
    "    \n",
    "    Par√¢metros:\n",
    "        - model: modelo treinado (ex: DecisionTree, GBC, GBR)\n",
    "        - X: dados de entrada (DataFrame ou array)\n",
    "        - max_display: n√∫mero m√°ximo de features no gr√°fico\n",
    "        - nome: t√≠tulo opcional a ser inclu√≠do nos gr√°ficos\n",
    "    \"\"\"\n",
    "    \n",
    "    modelos_problema = isinstance(model, DecisionTreeClassifier)\n",
    "    modelos_sem_problema = isinstance(model, (\n",
    "        GradientBoostingClassifier,\n",
    "        DecisionTreeRegressor,\n",
    "        GradientBoostingRegressor\n",
    "    ))\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    (f\"shap_values.shape = {shap_values.shape}, X.shape = {X.shape}\")\n",
    "    \n",
    "    if not modelos_problema:\n",
    "        if not modelos_sem_problema:\n",
    "            print(\"‚ö†Ô∏è Tipo de modelo n√£o identificado, tentando procedimento padr√£o\")\n",
    "            if shap_values.shape != X.shape:\n",
    "                raise AssertionError(f\"shap_values.shape = {shap_values.shape}, X.shape = {X.shape}\")\n",
    "                return\n",
    "        \n",
    "        print(\"üîç Gerando explicabilidade global do modelo...\")\n",
    "\n",
    "        \n",
    "\n",
    "        shap.summary_plot(shap_values, X, plot_type=\"bar\", max_display=max_display, show=False)\n",
    "        if nome:\n",
    "            plt.title(f\"{nome} ‚Äî Import√¢ncia global\")\n",
    "        plt.show()\n",
    "\n",
    "        shap.summary_plot(shap_values, X, max_display=max_display, show=False)\n",
    "        if nome:\n",
    "            plt.title(f\"{nome} ‚Äî Distribui√ß√£o dos impactos\")\n",
    "        plt.show()\n",
    "    \n",
    "    elif isinstance(model, DecisionTreeClassifier):\n",
    "        print(f\"shap_values.shape = {shap_values.shape}, X.shape = {X.shape}\")\n",
    "        class_names = model.classes_\n",
    "\n",
    "        _, _, n_classes = shap_values.shape\n",
    "        for i in range(n_classes):\n",
    "            \n",
    "            print(f\"\\nüìä {target_name}: {i}' ‚Äî Explica√ß√£o global\")\n",
    "            shap.summary_plot(shap_values[:, :, i], X, plot_type=\"bar\", max_display=max_display, show=False)\n",
    "            if nome:\n",
    "                plt.title(f\"{nome} ‚Äî {target_name}: {i}' ‚Äî Import√¢ncia global\")\n",
    "            plt.show()\n",
    "\n",
    "            print(f\"üìà {target_name}: {i}' ‚Äî Distribui√ß√£o dos impactos\")\n",
    "            shap.summary_plot(shap_values[:, :, i], X, max_display=max_display, show=False)\n",
    "            if nome:\n",
    "                plt.title(f\"{nome} ‚Äî {target_name}: {i}' ‚Äî Distribui√ß√£o dos impactos\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_individual(index, model, X_train):\n",
    "    import shap\n",
    "    from scipy.special import expit\n",
    "    import matplotlib.pyplot as plt\n",
    "    \"\"\"\n",
    "    üß† Explicabilidade local com SHAP (vers√£o waterfall).\n",
    "    Mostra o impacto de cada feature + exibe a probabilidade prevista no gr√°fico.\n",
    "    \"\"\"\n",
    "    # Obter valores SHAP\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    instance = X_train.iloc[[index]]\n",
    "\n",
    "    # Corrigir acesso ao escalar\n",
    "    expected_value = explainer.expected_value[0]\n",
    "    fx = float(shap_values[index].sum() + expected_value)\n",
    "    prob = float(expit(fx))\n",
    "\n",
    "    # Construir explica√ß√£o\n",
    "    explanation = shap.Explanation(\n",
    "        values=shap_values[index],\n",
    "        base_values=expected_value,\n",
    "        data=instance.values[0],\n",
    "        feature_names=instance.columns\n",
    "    )\n",
    "\n",
    "    # Plot com t√≠tulo seguro (sem emoji)\n",
    "    shap.plots.waterfall(explanation, show=False)\n",
    "    plt.title(f\"SHAP Waterfall ‚Äî Inst√¢ncia {index} | Prob. prevista: {prob:.2f}\", fontsize=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ae6d8",
   "metadata": {},
   "source": [
    "## üöÄ Pipeline Models e Mitiga√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_baseline(X_train, X_test, y_train, y_test, weights=None, label=\"Baseline\"):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \"\"\"\n",
    "    Pipeline simples de treinamento e avalia√ß√£o com GradientBoostingClassifier.\n",
    "    \"\"\"\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train, sample_weight=weights)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nüîç Resultados para: {label}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82024753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_fairshap(X_train, X_test, y_train, y_test,\n",
    "                       protected_attribute_col,\n",
    "                       privileged_value, unprivileged_value,\n",
    "                       label_favorable, label_unfavorable\n",
    "                       ):\n",
    "    from fairSV.fair_shapley import FairShapley\n",
    "    \"\"\"\n",
    "    Pipeline com FairShap aplicado, incluindo:\n",
    "    - C√°lculo da matriz SV.\n",
    "    - C√°lculo dos Shapley Values fairness-aware.\n",
    "    - Gera√ß√£o de pesos baseados em uma m√©trica de justi√ßa.\n",
    "\n",
    "    Par√¢metros:\n",
    "    - X_train, X_test: Dados de treino e teste (DataFrame ou array).\n",
    "    - y_train, y_test: Labels.\n",
    "    - protected_attribute_col: Nome da coluna do atributo sens√≠vel.\n",
    "    - privileged_value: Valor do grupo privilegiado (ex.: 1).\n",
    "    - unprivileged_value: Valor do grupo n√£o privilegiado (ex.: 0).\n",
    "    - label_favorable: Label favor√°vel (ex.: 0).\n",
    "    - label_unfavorable: Label desfavor√°vel (ex.: 1).\n",
    "\n",
    "    Retorna:\n",
    "    - weights: Vetor de pesos gerados a partir de Equal Opportunity Normalizado.\n",
    "    - fair_sv_extractor: Objeto FairShapley com todos os resultados e m√©tricas.\n",
    "    \"\"\"\n",
    "    # ‚úÖ Extrair os valores do atributo sens√≠vel no conjunto de teste\n",
    "    protected_values = X_test[protected_attribute_col].values\n",
    "\n",
    "    # ‚úîÔ∏è Definir o dicion√°rio do FairShap\n",
    "    protected_attributes_dict = {\n",
    "        'values': protected_values,\n",
    "        'privileged_protected_attribute': privileged_value,\n",
    "        'unprivileged_protected_attribute': unprivileged_value,\n",
    "        'favorable_label': label_favorable,\n",
    "        'unfavorable_label': label_unfavorable\n",
    "    }\n",
    "\n",
    "    # üöÄ Criar o objeto FairShap\n",
    "    fair_sv_extractor = FairShapley(\n",
    "        X_train.values, y_train,\n",
    "        X_test.values, y_test,\n",
    "        protected_attributes_dict=protected_attributes_dict,\n",
    "        show_plot=False,\n",
    "        calculate_2dim=True\n",
    "    )\n",
    "\n",
    "    # üîç Encontrar o melhor K\n",
    "    best_k, _, _ = fair_sv_extractor.get_best_K()\n",
    "\n",
    "    # üî¢ Calcular a matriz SV\n",
    "    _ = fair_sv_extractor.get_SV_matrix(K=best_k)\n",
    "\n",
    "    # üî¢ Calcular os Shapley Values fairness-aware\n",
    "    fair_sv_extractor.get_sv_arrays()\n",
    "\n",
    "    # üéØ Gera√ß√£o dos pesos com base na Equal Opportunity\n",
    "    sv_eop = fair_sv_extractor.sv_equal_opportunity_difference\n",
    "    #normaliza√ß√£o\n",
    "    weights = (sv_eop - np.min(sv_eop)) / (np.max(sv_eop) - np.min(sv_eop))\n",
    "\n",
    "    return weights, fair_sv_extractor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
